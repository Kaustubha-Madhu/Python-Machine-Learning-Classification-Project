{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing essential libraries\n",
    "import numpy as np # used for handling numbers\n",
    "import pandas as pd # used for handling the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # used for feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import statsmodels.api as sm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split # used for splitting training and testing data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils.testing import  ignore_warnings\n",
    "\n",
    "from sklearn.impute import SimpleImputer # used for handling missing data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # used for encoding categorical data\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data from csv files\n",
    "\n",
    "df=pd.read_csv(\"Bank_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 17 columns):\n",
      "age           1984 non-null float64\n",
      "job           1989 non-null object\n",
      "marital       2000 non-null object\n",
      "education     1871 non-null object\n",
      "default       2000 non-null object\n",
      "balance       2000 non-null int64\n",
      "housing       2000 non-null object\n",
      "loan          2000 non-null object\n",
      "contact       1811 non-null object\n",
      "day           2000 non-null int64\n",
      "month         2000 non-null object\n",
      "duration      2000 non-null int64\n",
      "campaign      2000 non-null int64\n",
      "pdays         2000 non-null int64\n",
      "previous      2000 non-null int64\n",
      "poutcome      149 non-null object\n",
      "is_success    2000 non-null object\n",
      "dtypes: float64(1), int64(6), object(10)\n",
      "memory usage: 265.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() #Number of non-null values in different feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age             16\n",
       "job             11\n",
       "marital          0\n",
       "education      129\n",
       "default          0\n",
       "balance          0\n",
       "housing          0\n",
       "loan             0\n",
       "contact        189\n",
       "day              0\n",
       "month            0\n",
       "duration         0\n",
       "campaign         0\n",
       "pdays            0\n",
       "previous         0\n",
       "poutcome      1851\n",
       "is_success       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() #showing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe() gives us the mean of age to be 41.17, rounding it to 41. We impute 41 with null values\n",
    "df[\"age\"].fillna(\"41.0\", inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age              0\n",
       "job             11\n",
       "marital          0\n",
       "education      129\n",
       "default          0\n",
       "balance          0\n",
       "housing          0\n",
       "loan             0\n",
       "contact        189\n",
       "day              0\n",
       "month            0\n",
       "duration         0\n",
       "campaign         0\n",
       "pdays            0\n",
       "previous         0\n",
       "poutcome      1851\n",
       "is_success       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() #showing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"job\"].fillna(\"blue-collar\", inplace = True)  \n",
    "# Imputing the null values in the feature 'Job'with Blue-Collar as maximum values are blue-collar which was checked above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age              0\n",
       "job              0\n",
       "marital          0\n",
       "education      129\n",
       "default          0\n",
       "balance          0\n",
       "housing          0\n",
       "loan             0\n",
       "contact        189\n",
       "day              0\n",
       "month            0\n",
       "duration         0\n",
       "campaign         0\n",
       "pdays            0\n",
       "previous         0\n",
       "poutcome      1851\n",
       "is_success       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() #showing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same with education, maximum is secondary\n",
    "# Imputing the null values in the feature 'Education'\n",
    "df[\"education\"].fillna(\"secondary\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age              0\n",
       "job              0\n",
       "marital          0\n",
       "education        0\n",
       "default          0\n",
       "balance          0\n",
       "housing          0\n",
       "loan             0\n",
       "contact        189\n",
       "day              0\n",
       "month            0\n",
       "duration         0\n",
       "campaign         0\n",
       "pdays            0\n",
       "previous         0\n",
       "poutcome      1851\n",
       "is_success       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() #showing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the null values in this feature are very high, Hence dropping this column would be the best.\n",
    "#dropping variable 'poutcome'\n",
    "del df['poutcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This feature 'default' is very skewed, so we can delete this column\n",
    "del df['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Contact' variable does not have any impact on target variable so we can drop this variable as almost all the values are cellular.\n",
    "del df['contact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           0\n",
       "job           0\n",
       "marital       0\n",
       "education     0\n",
       "balance       0\n",
       "housing       0\n",
       "loan          0\n",
       "day           0\n",
       "month         0\n",
       "duration      0\n",
       "campaign      0\n",
       "pdays         0\n",
       "previous      0\n",
       "is_success    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no more missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating Target variable from other variables\n",
    "dataset_Y = df['is_success']\n",
    "dataset_X = df[df.columns[0:12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  age  balance  day  duration  campaign  pdays  job_admin.  job_blue-collar  \\\n",
      "0  58     2143    5       261         1     -1           0                0   \n",
      "1  44       29    5       151         1     -1           0                0   \n",
      "2  33        2    5        76         1     -1           0                0   \n",
      "3  47     1506    5        92         1     -1           0                1   \n",
      "4  33        1    5       198         1     -1           0                1   \n",
      "\n",
      "   job_entrepreneur  job_housemaid  ...  month_July  month_June  \\\n",
      "0                 0              0  ...           0           1   \n",
      "1                 0              0  ...           0           1   \n",
      "2                 1              0  ...           0           1   \n",
      "3                 0              0  ...           0           1   \n",
      "4                 0              0  ...           0           1   \n",
      "\n",
      "   month_September  month_apr  month_feb  month_jan  month_mar  month_may  \\\n",
      "0                0          0          0          0          0          0   \n",
      "1                0          0          0          0          0          0   \n",
      "2                0          0          0          0          0          0   \n",
      "3                0          0          0          0          0          0   \n",
      "4                0          0          0          0          0          0   \n",
      "\n",
      "   month_nov  month_oct  \n",
      "0          0          0  \n",
      "1          0          0  \n",
      "2          0          0  \n",
      "3          0          0  \n",
      "4          0          0  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "#converting Independent Categorical into Numeriacal by creating Dummy variables\n",
    "dataset_X_dummy = pd.get_dummies(dataset_X , columns =['job','marital','education','housing','loan','month'])\n",
    "print(dataset_X_dummy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# spliting the data\n",
    "# Creating Test and Train Data\n",
    "#converting dataframe into numpy Array\n",
    "X = dataset_X_dummy.values\n",
    "Y = dataset_Y.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org, X_test_org,Y_train, Y_test = train_test_split(X,Y,random_state=0, test_size=0.2)\n",
    "\n",
    "# Scaling using MinMax. Best because we want to retain the outliers in the data, we are using the MinMax Scaler.\n",
    "scaler= MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 39)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 39)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Models\n",
    "\n",
    "# KNN Classifier\n",
    "#K=7 has the best Test score and the difference between train and test score is also the least.(from project-1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "knn = KNeighborsClassifier(7)\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KNN Classifier', 'k=7', 0.960625, 0.965]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the reporting table with all models, hyper parameters and test as well as train accuracy from Project-1\n",
    "report_table = [['KNN Classifier', 'k=7', knn.score(X_train, Y_train), knn.score(X_test, Y_test)]]\n",
    "report_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.92\n",
      "Test set score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# For Logistic Regression, the best Hyper Parameters are C = 0.10 and Penality = l2, according to project-1 \n",
    "log = LogisticRegression(penalty = 'l2', C = 0.10, solver=\"lbfgs\")\n",
    "\n",
    "log.fit(X_train, Y_train)\n",
    "log.fit(X_test, Y_test)\n",
    "\n",
    "print(\"Train set score: {:.2f}\".format(log.score(X_train, Y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(log.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KNN Classifier', 'k=7', 0.960625, 0.965],\n",
       " ['Logistic Regression', 'C=0.10, Penality=l2', 0.965625, 0.9675]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table = report_table + [['Logistic Regression', 'C=0.10, Penality=l2', log.score(X_train, Y_train), log.score(X_test, Y_test)]]\n",
    "report_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.988\n",
      "Accuracy on test set: 0.985\n"
     ]
    }
   ],
   "source": [
    "# Decision Trees, the best according to project-1\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "dtree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "dtree.fit(X_train, Y_train)\n",
    "\n",
    "pred_dtree = dtree.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dtree.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dtree.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KNN Classifier', 'k=7', 0.960625, 0.965],\n",
       " ['Logistic Regression', 'C=0.10, Penality=l2', 0.965625, 0.9675],\n",
       " ['Decision Tree', 'max_depth=4', 0.988125, 0.985]]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table = report_table + [['Decision Tree', 'max_depth=4', dtree.score(X_train, Y_train), dtree.score(X_test, Y_test)]]\n",
    "report_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9825\n",
      "0.9675\n"
     ]
    }
   ],
   "source": [
    "# The best svm according to project-1\n",
    "# SVM with kernel trick\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "\n",
    "svm = SVC(kernel='rbf', gamma=0.01, C=100, probability= True)\n",
    "svm.fit(X_train, Y_train)\n",
    "print( svm.score(X_train, Y_train))\n",
    "print( svm.score(X_test, Y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KNN Classifier', 'k=7', 0.960625, 0.965],\n",
       " ['Logistic Regression', 'C=0.10, Penality=l2', 0.965625, 0.9675],\n",
       " ['Decision Tree', 'max_depth=4', 0.988125, 0.985],\n",
       " ['SVC', 'Kernel= RBF, C=100, gamma=0.01', 0.9825, 0.9675]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table = report_table + [['SVC', 'Kernel= RBF, C=100, gamma=0.01', svm.score(X_train, Y_train), svm.score(X_test, Y_test)]]\n",
    "report_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984375\n",
      "0.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Softmax Regression from project-1\n",
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10)\n",
    "softmax_reg.fit(X_train, Y_train)\n",
    "\n",
    "print( softmax_reg.score(X_train,Y_train))\n",
    "print( softmax_reg.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KNN Classifier', 'k=7', 0.960625, 0.965],\n",
       " ['Logistic Regression', 'C=0.10, Penality=l2', 0.965625, 0.9675],\n",
       " ['Decision Tree', 'max_depth=4', 0.988125, 0.985],\n",
       " ['SVC', 'Kernel= RBF, C=100, gamma=0.01', 0.9825, 0.9675],\n",
       " ['Softmax Regression', 'C=10', 0.984375, 0.9725]]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table = report_table + [['Softmax Regression', 'C=10', softmax_reg.score(X_train, Y_train), softmax_reg.score(X_test, Y_test)]]\n",
    "report_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9675\n",
      "KNeighborsClassifier 0.965\n",
      "SVC 0.9675\n",
      "VotingClassifier 0.9675\n"
     ]
    }
   ],
   "source": [
    "# Hard Voting\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_hard = VotingClassifier(estimators=[('lr', log), ('knn', knn), ('svc', svm)], voting='hard')\n",
    "voting_hard.fit(X_train, Y_train)\n",
    "\n",
    "for clf in (log, knn, svm, voting_hard):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9675\n",
      "KNeighborsClassifier 0.965\n",
      "SVC 0.9675\n",
      "VotingClassifier 0.9725\n"
     ]
    }
   ],
   "source": [
    "# Soft Voting\n",
    "\n",
    "voting_soft = VotingClassifier(estimators=[('lr', log), ('knn', knn), ('svc', svm)], voting = 'soft')\n",
    "voting_soft.fit(X_train, Y_train)\n",
    "\n",
    "for clf_soft in (log, knn, svm, voting_soft):\n",
    "    clf_soft.fit(X_train, Y_train)\n",
    "    y_prediction = clf_soft.predict(X_test)\n",
    "    print(clf_soft.__class__.__name__, accuracy_score(Y_test, y_prediction))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "# bagging with Decision Tree\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "bag_dtree = BaggingClassifier(dtree, n_estimators=500, max_samples=100, bootstrap=True, random_state=0, oob_score=True)\n",
    "\n",
    "bag_dtree.fit(X_train, Y_train)\n",
    "y_pred_bag_dtree = bag_dtree.predict(X_test)\n",
    "\n",
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, y_pred_bag_dtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.98\n",
      "Test score: 0.98\n"
     ]
    }
   ],
   "source": [
    "bag_dtree.fit(X_train, Y_train)\n",
    "print('Train score: {:.2f}'.format(bag_dtree.score(X_train, Y_train)))\n",
    "print('Test score: {:.2f}'.format(bag_dtree.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n"
     ]
    }
   ],
   "source": [
    "# Bagging with Softmax Regression\n",
    "\n",
    "bag_softmax = BaggingClassifier(softmax_reg, n_estimators=100, max_samples=100, bootstrap=True, random_state=0, oob_score=True)\n",
    "bag_softmax.fit(X_train, Y_train)\n",
    "y_pred_softmax = bag_softmax.predict(X_test)\n",
    "\n",
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, y_pred_softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.97\n",
      "Test score: 0.97\n"
     ]
    }
   ],
   "source": [
    "bag_softmax.fit(X_train, Y_train)\n",
    "print('Train score: {:.2f}'.format(bag_softmax.score(X_train, Y_train)))\n",
    "print('Test score: {:.2f}'.format(bag_softmax.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8975\n"
     ]
    }
   ],
   "source": [
    "# Pasting with decision tree\n",
    "\n",
    "paste_dtree = BaggingClassifier(dtree, n_estimators=100, max_samples=10, bootstrap=False, random_state=0)\n",
    "\n",
    "paste_dtree.fit(X_train, Y_train)\n",
    "y_pred_paste_dtree = paste_dtree.predict(X_test)\n",
    "\n",
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, y_pred_paste_dtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.89\n",
      "Test score: 0.90\n"
     ]
    }
   ],
   "source": [
    "paste_dtree.fit(X_train, Y_train)\n",
    "print('Train score: {:.2f}'.format(paste_dtree.score(X_train, Y_train)))\n",
    "print('Test score: {:.2f}'.format(paste_dtree.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9675\n"
     ]
    }
   ],
   "source": [
    "# Pasting with softmax Regression\n",
    "\n",
    "paste_softmax = BaggingClassifier(softmax_reg, n_estimators=100, max_samples=100, bootstrap=False, random_state=0)\n",
    "paste_softmax.fit(X_train, Y_train)\n",
    "y_pred_paste_softmax = paste_softmax.predict(X_test)\n",
    "\n",
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, y_pred_paste_softmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.97\n",
      "Test score: 0.97\n"
     ]
    }
   ],
   "source": [
    "paste_softmax.fit(X_train, Y_train)\n",
    "print('Train score: {:.2f}'.format(paste_softmax.score(X_train, Y_train)))\n",
    "print('Test score: {:.2f}'.format(paste_softmax.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADA Boosting with Logistic Regression\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators' : [5, 10, 15,50,100,500,200,300,400]\n",
    "    }\n",
    "\n",
    "ada = AdaBoostClassifier(base_estimator=LogisticRegression(penalty = 'l2', C = 0.10, solver=\"lbfgs\"),algorithm='SAMME')\n",
    "clf = GridSearchCV(ada,param_grid, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME',\n",
       "                                          base_estimator=LogisticRegression(C=0.1,\n",
       "                                                                            class_weight=None,\n",
       "                                                                            dual=False,\n",
       "                                                                            fit_intercept=True,\n",
       "                                                                            intercept_scaling=1,\n",
       "                                                                            l1_ratio=None,\n",
       "                                                                            max_iter=100,\n",
       "                                                                            multi_class='warn',\n",
       "                                                                            n_jobs=None,\n",
       "                                                                            penalty='l2',\n",
       "                                                                            random_state=None,\n",
       "                                                                            solver='lbfgs',\n",
       "                                                                            tol=0.0001,\n",
       "                                                                            verbose=0,\n",
       "                                                                            warm_start=False),\n",
       "                                          learning_rate=1.0, n_estimators=50,\n",
       "                                          random_state=None),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
       "                         'n_estimators': [5, 10, 15, 50, 100, 500, 200, 300,\n",
       "                                          400]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score 0.9882744514433413\n",
      "{'learning_rate': 0.3, 'n_estimators': 500}\n",
      "AdaBoostClassifier(algorithm='SAMME',\n",
      "                   base_estimator=LogisticRegression(C=0.1, class_weight=None,\n",
      "                                                     dual=False,\n",
      "                                                     fit_intercept=True,\n",
      "                                                     intercept_scaling=1,\n",
      "                                                     l1_ratio=None,\n",
      "                                                     max_iter=100,\n",
      "                                                     multi_class='warn',\n",
      "                                                     n_jobs=None, penalty='l2',\n",
      "                                                     random_state=None,\n",
      "                                                     solver='lbfgs', tol=0.0001,\n",
      "                                                     verbose=0,\n",
      "                                                     warm_start=False),\n",
      "                   learning_rate=0.3, n_estimators=500, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best cross-validation score\", clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_log = AdaBoostClassifier(base_estimator=log, n_estimators=500, random_state=None, learning_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.94\n",
      "Test score: 0.94\n"
     ]
    }
   ],
   "source": [
    "ada_log.fit(X_train, Y_train)\n",
    "\n",
    "print('Train score: {:.2f}'.format(ada_log.score(X_train, Y_train)))\n",
    "print('Test score: {:.2f}'.format(ada_log.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.97\n"
     ]
    }
   ],
   "source": [
    "y_pred_ada_log = ada_log.predict_proba(X_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ada_roc_auc = roc_auc_score(Y_test, y_pred_ada_log)\n",
    "\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADA Boosting with SVC\n",
    "adaboost_svm = AdaBoostClassifier(base_estimator=svm, n_estimators=50, learning_rate=1.0, random_state=42)\n",
    "\n",
    "adaboost_svm.fit(X_train, Y_train)\n",
    "y_adaboost_svm = adaboost_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.89\n",
      "Test score: 0.90\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {:.2f}'.format(adaboost_svm.score(X_train, Y_train)))\n",
    "print('Test score: {:.2f}'.format(adaboost_svm.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=1.0, loss='deviance', max_depth=4,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=3,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=42, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "# Have to add grid Search\n",
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "grad = GradientBoostingClassifier(max_depth=4, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "grad.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "#train\n",
    "pca.fit(X_train)\n",
    "#transform\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 39)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_reduced = PCA(n_components=0.95)\n",
    "pca_reduced.fit(X_train)\n",
    "X_train_reduced = pca_reduced.transform(X_train)\n",
    "X_test_reduced = pca_reduced.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_reduced.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47000451, 0.40873843, 0.33574795, 0.24336254, 0.23241167,\n",
       "       0.20134908, 0.1796221 , 0.14875541, 0.1309573 , 0.11462453,\n",
       "       0.09127328, 0.06899766, 0.06231721, 0.05099472, 0.03873231,\n",
       "       0.03018085, 0.02812112, 0.02633344, 0.02344001])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_reduced.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]}\n"
     ]
    }
   ],
   "source": [
    "# PCA with Models\n",
    "# KNN\n",
    "\n",
    "k_list = list(range(1,51))\n",
    "param_grid = dict(n_neighbors=k_list)\n",
    "print(param_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29, 30, ...]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridknn = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='roc_auc')\n",
    "gridknn.fit(X_train_reduced, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score 0.9424882629107981\n",
      "{'n_neighbors': 35}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=35, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print('Best cross-validation score',gridknn.best_score_)\n",
    "print(gridknn.best_params_)\n",
    "print(gridknn.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.935625\n",
      "test score 0.9375\n"
     ]
    }
   ],
   "source": [
    "knn_pca = KNeighborsClassifier(35)\n",
    "knn_pca.fit(X_train_reduced, Y_train)\n",
    "print('train score',knn_pca.score(X_train_reduced, Y_train))\n",
    "print('test score',knn_pca.score(X_test_reduced, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn_pca.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[358   1]\n",
      " [ 24  17]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(Y_test, knn_pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KNN Classifier', 'k=35', 0.935625, 0.9375]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table_pca = [['KNN Classifier', 'k=35', knn_pca.score(X_train_reduced, Y_train), knn_pca.score(X_test_reduced, Y_test)]]\n",
    "report_table_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  PCA with Logistic Regression\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "penalty = ['l1', 'l2']\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "grid_lg = GridSearchCV(logistic, hyperparameters, cv=10, scoring='accuracy')\n",
    "grid_lg.fit(X_train_reduced, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971875\n",
      "{'C': 100, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_lg.best_score_)\n",
    "print(grid_lg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.973125\n",
      "test score 0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "log_pca = LogisticRegression(penalty = 'l1', C = 100)\n",
    "\n",
    "log_pca.fit(X_train_reduced, Y_train)\n",
    "print('train score',log_pca.score(X_train_reduced, Y_train))\n",
    "print('test score',log_pca.score(X_test_reduced, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KNN Classifier', 'k=35', 0.935625, 0.9375],\n",
       " ['Logistic Regression', 'C=100, penality=l1', 0.973125, 0.9775]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table_pca = report_table_pca + [['Logistic Regression', 'C=100, penality=l1', log_pca.score(X_train_reduced, Y_train), log_pca.score(X_test_reduced, Y_test)]]\n",
    "report_table_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with Softmax Regression\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "softmax_pca = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score 0.001 0.8975\n",
      "test score 0.01 0.9225\n",
      "test score 0.1 0.96\n",
      "test score 1 0.97\n",
      "test score 10 0.9775\n",
      "test score 100 0.9775\n",
      "test score 1000 0.9775\n"
     ]
    }
   ],
   "source": [
    "for C in C:\n",
    "    softmax_pca = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=C)\n",
    "    softmax_pca.fit(X_train_reduced, Y_train)\n",
    "    print('test score',C,softmax_pca.score(X_test_reduced, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.97375\n",
      "test score 0.9775\n"
     ]
    }
   ],
   "source": [
    "# the best C for softmax Regression is C=10\n",
    "softmax_pca1 = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10)\n",
    "softmax_pca1.fit(X_train_reduced, Y_train)\n",
    "print('train score',softmax_pca1.score(X_train_reduced, Y_train))\n",
    "print('test score',softmax_pca1.score(X_test_reduced, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KNN Classifier', 'k=35', 0.935625, 0.9375],\n",
       " ['Logistic Regression', 'C=100, penality=l1', 0.973125, 0.9775],\n",
       " ['Softmax Regression', 'C=10', 0.973125, 0.9775]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table_pca = report_table_pca + [['Softmax Regression', 'C=10', log_pca.score(X_train_reduced, Y_train), log_pca.score(X_test_reduced, Y_test)]]\n",
    "report_table_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19]}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA with Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "param_grid={'max_depth': list(range(1,20))}\n",
    "param_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                       13, 14, 15, 16, 17, 18, 19]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dt = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='roc_auc')\n",
    "grid_dt.fit(X_train_reduced, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.898141627543036\n",
      "{'max_depth': 3}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(grid_dt.best_score_)\n",
    "print(grid_dt.best_params_)\n",
    "print(grid_dt.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth= 3)\n",
    "dt.fit(X_train_reduced, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.965\n",
      "test score 0.96\n"
     ]
    }
   ],
   "source": [
    "print('train score',dt.score(X_train_reduced, Y_train))\n",
    "print('test score',dt.score(X_test_reduced, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KNN Classifier', 'k=35', 0.935625, 0.9375],\n",
       " ['Logistic Regression', 'C=100, penality=l1', 0.973125, 0.9775],\n",
       " ['Softmax Regression', 'C=10', 0.973125, 0.9775],\n",
       " ['Decision Tree', 'max_depth=3', 0.965, 0.96]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table_pca = report_table_pca + [['Decision Tree', 'max_depth=3', dt.score(X_train_reduced, Y_train), dt.score(X_test_reduced, Y_test)]]\n",
    "report_table_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA with Linear SVC\n",
    "\n",
    "svc_lin = LinearSVC()\n",
    "param_grid = {'C':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_svc_lin = GridSearchCV(svc_lin, param_grid, cv = 10, scoring='accuracy')\n",
    "grid_svc_lin.fit(X_train_reduced,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97125\n",
      "{'C': 10}\n"
     ]
    }
   ],
   "source": [
    "print(grid_svc_lin.best_score_)\n",
    "print(grid_svc_lin.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.974375\n",
      "test score 0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiv Vadlamudi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lsc = LinearSVC(C=10)\n",
    "\n",
    "lsc.fit(X_train_reduced, Y_train)\n",
    "print('train score',lsc.score(X_train_reduced, Y_train))\n",
    "print('test score',lsc.score(X_test_reduced, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KNN Classifier', 'k=35', 0.935625, 0.9375],\n",
       " ['Logistic Regression', 'C=100, penality=l1', 0.973125, 0.9775],\n",
       " ['Softmax Regression', 'C=10', 0.973125, 0.9775],\n",
       " ['Decision Tree', 'max_depth=3', 0.965, 0.96],\n",
       " ['Linear SVC', 'C=10', 0.974375, 0.9775]]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table_pca = report_table_pca + [['Linear SVC', 'C=10', lsc.score(X_train_reduced, Y_train), lsc.score(X_test_reduced, Y_test)]]\n",
    "report_table_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'gamma': [0.01, 0.1, 1, 10, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA with RBF Kernel\n",
    "from sklearn.svm import SVC\n",
    "#Grid Search with Cross-Validation using cv=10\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_svc1 = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=10, scoring = 'accuracy', n_jobs=-1)\n",
    "grid_svc1.fit(X_train_reduced,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.01}\n",
      "0.9675\n"
     ]
    }
   ],
   "source": [
    "print(grid_svc1.best_params_)\n",
    "print(grid_svc1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.969375\n",
      "test score 0.975\n"
     ]
    }
   ],
   "source": [
    "svc_pca = SVC(kernel='rbf', C=100, gamma=0.01)\n",
    "\n",
    "svc_pca.fit(X_train_reduced, Y_train)\n",
    "print('train score',svc_pca.score(X_train_reduced, Y_train))\n",
    "print('test score',svc_pca.score(X_test_reduced, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KNN Classifier', 'k=35', 0.935625, 0.9375],\n",
       " ['Logistic Regression', 'C=100, penality=l1', 0.973125, 0.9775],\n",
       " ['Softmax Regression', 'C=10', 0.973125, 0.9775],\n",
       " ['Decision Tree', 'max_depth=3', 0.965, 0.96],\n",
       " ['Linear SVC', 'C=10', 0.974375, 0.9775],\n",
       " [sklearn.svm.classes.SVC, 'Kernel=RBF, C=100, Gamma=0.01', 0.969375, 0.975]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table_pca = report_table_pca + [['SVC', 'Kernel=RBF, C=100, Gamma=0.01', svc_pca.score(X_train_reduced, Y_train), svc_pca.score(X_test_reduced, Y_test)]]\n",
    "report_table_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>Model parameter</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>k=35</td>\n",
       "      <td>0.935625</td>\n",
       "      <td>0.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>C=100, penality=l1</td>\n",
       "      <td>0.973125</td>\n",
       "      <td>0.9775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Softmax Regression</td>\n",
       "      <td>Softmax Regression</td>\n",
       "      <td>C=10</td>\n",
       "      <td>0.973125</td>\n",
       "      <td>0.9775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>max_depth=3</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>C=10</td>\n",
       "      <td>0.974375</td>\n",
       "      <td>0.9775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;class 'sklearn.svm.classes.SVC'&gt;</td>\n",
       "      <td>&lt;class 'sklearn.svm.classes.SVC'&gt;</td>\n",
       "      <td>Kernel=RBF, C=100, Gamma=0.01</td>\n",
       "      <td>0.969375</td>\n",
       "      <td>0.9750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Model name  \\\n",
       "Model name                                                             \n",
       "KNN Classifier                                        KNN Classifier   \n",
       "Logistic Regression                              Logistic Regression   \n",
       "Softmax Regression                                Softmax Regression   \n",
       "Decision Tree                                          Decision Tree   \n",
       "Linear SVC                                                Linear SVC   \n",
       "<class 'sklearn.svm.classes.SVC'>  <class 'sklearn.svm.classes.SVC'>   \n",
       "\n",
       "                                                 Model parameter  \\\n",
       "Model name                                                         \n",
       "KNN Classifier                                              k=35   \n",
       "Logistic Regression                           C=100, penality=l1   \n",
       "Softmax Regression                                          C=10   \n",
       "Decision Tree                                        max_depth=3   \n",
       "Linear SVC                                                  C=10   \n",
       "<class 'sklearn.svm.classes.SVC'>  Kernel=RBF, C=100, Gamma=0.01   \n",
       "\n",
       "                                   Train accuracy  Test accuracy  \n",
       "Model name                                                        \n",
       "KNN Classifier                           0.935625         0.9375  \n",
       "Logistic Regression                      0.973125         0.9775  \n",
       "Softmax Regression                       0.973125         0.9775  \n",
       "Decision Tree                            0.965000         0.9600  \n",
       "Linear SVC                               0.974375         0.9775  \n",
       "<class 'sklearn.svm.classes.SVC'>        0.969375         0.9750  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report with PCA\n",
    "report = pd.DataFrame(report_table_pca,columns = ['Model name', 'Model parameter', 'Train accuracy', 'Test accuracy'])\n",
    "report.index = report['Model name']\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>Model parameter</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>k=7</td>\n",
       "      <td>0.960625</td>\n",
       "      <td>0.9650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>C=0.10, Penality=l2</td>\n",
       "      <td>0.965625</td>\n",
       "      <td>0.9675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>max_depth=4</td>\n",
       "      <td>0.988125</td>\n",
       "      <td>0.9850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Kernel= RBF, C=100, gamma=0.01</td>\n",
       "      <td>0.982500</td>\n",
       "      <td>0.9675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Softmax Regression</td>\n",
       "      <td>Softmax Regression</td>\n",
       "      <td>C=10</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.9725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model name                 Model parameter  \\\n",
       "Model name                                                                 \n",
       "KNN Classifier            KNN Classifier                             k=7   \n",
       "Logistic Regression  Logistic Regression             C=0.10, Penality=l2   \n",
       "Decision Tree              Decision Tree                     max_depth=4   \n",
       "SVC                                  SVC  Kernel= RBF, C=100, gamma=0.01   \n",
       "Softmax Regression    Softmax Regression                            C=10   \n",
       "\n",
       "                     Train accuracy  Test accuracy  \n",
       "Model name                                          \n",
       "KNN Classifier             0.960625         0.9650  \n",
       "Logistic Regression        0.965625         0.9675  \n",
       "Decision Tree              0.988125         0.9850  \n",
       "SVC                        0.982500         0.9675  \n",
       "Softmax Regression         0.984375         0.9725  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report Before using PCA\n",
    "report_1 = pd.DataFrame(report_table,columns = ['Model name', 'Model parameter', 'Train accuracy', 'Test accuracy'])\n",
    "report_1.index = report_1['Model name']\n",
    "report_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9775\n",
      "{'batch_size': 10, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=39, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model, verbose = 0)\n",
    "\n",
    "param_grid = {'batch_size':[10,20,30,40] , 'epochs':[10, 50, 100]}\n",
    "grid_deep = GridSearchCV(estimator= model, param_grid = param_grid, cv = 5, scoring = 'accuracy')\n",
    "\n",
    "grid_deep.fit(X_train, Y_train)\n",
    "print(grid_deep.best_score_)\n",
    "print(grid_deep.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.99\n",
      "Test score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {:.2f}'.format(grid_deep.score(X_train, Y_train)))\n",
    "print('Test score: {:.2f}'.format(grid_deep.score(X_test, Y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
